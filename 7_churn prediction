# =====================================================================
# ğŸ§  STEP 8: CHURN PREDICTION + TEMPORAL FORECASTING

# Title: Predicting Customer Churn and Forecasting Retention Trends
# Author: Maria Figueiredo
# Dataset: Online Retail (UCI Machine Learning Repository)

# =====================================================================
# ğŸ¯ OBJECTIVE
# This step combines machine learning (Random Forest) and time series orecasting (Meta Prophet) to predict customer churn and model how
# retention evolves over time.

# The analysis aims to identify *who* is likely to leave (classification) and *when* churn is likely to increase (forecasting),
# forming a complete â€œCustomer Churn Intelligence Systemâ€.

# Specifically, this step:
#   â–ª Builds behavioral RFM features (Recency, Frequency, Monetary).
#   â–ª Defines churn labels based on recency thresholds.
#   â–ª Trains a Random Forest classifier to predict churn risk.
#   â–ª Evaluates variable importance and interprets key behavioral drivers.
#   â–ª Forecasts monthly churn trends using Meta Prophet.
#   â–ª Integrates both perspectives into a strategic retention framework.

# =====================================================================
# ğŸ’¡ WHY THIS STEP MATTERS
# Churn is one of the most critical metrics in customer management.
# Acquiring a new customer can cost 5â€“7Ã— more than retaining an existing one.
# Predicting churn allows organizations to anticipate losses *before* they happen â€” enabling proactive reactivation and loyalty strategies.

# â–« Financially â†’ Reduces revenue leakage and improves lifetime value (CLV).
# â–« Strategically â†’ Strengthens retention programs and marketing efficiency.
# â–« Operationally â†’ Supports CRM automation and customer segmentation.

# Predictive churn analysis transforms reactive management into predictive intelligence, driving sustainable, customer-centric profitability.

# =====================================================================
# ğŸŒ VALUE FOR INDUSTRY AND SOCIETY
# â–« For Businesses:
#     - Enables proactive retention and reduces churn-driven losses.
#     - Optimizes marketing spending through targeted interventions.
#     - Supports stable revenue forecasting and planning.

# â–« For Society:
#     - Encourages fair, loyalty-based commercial relationships.
#     - Promotes responsible data use for retention rather than manipulation.
#     - Strengthens consumer trust through personalized, value-based engagement.

# =====================================================================
# ğŸ§­ CURRENT STEP
# This step follows Step 7 (Sales Forecasting) and closes the predictive analytics cycle by focusing on customer-level attrition.
# In this step we:
#   1ï¸âƒ£ Build RFM-based features (Recency, Frequency, Monetary).
#   2ï¸âƒ£ Define churn thresholds and label inactive customers.
#   3ï¸âƒ£ Train and evaluate a Random Forest model for churn prediction.
#   4ï¸âƒ£ Visualize feature importance and interpret behavioral drivers.
#   5ï¸âƒ£ Use Prophet to forecast churn evolution across future months.
#   6ï¸âƒ£ Integrate insights to form a unified, data-driven retention strategy.

# Together, these analyses connect *micro-level behavior* (individual churn risk) with *macro-level foresight* (temporal churn trends).

# =====================================================================
# ğŸ’¼ STRATEGIC CONTEXT
# This integrated churn prediction framework provides:
# â–ª Precision:Identification of customers most likely to leave.
# â–ª Timing:Forecast of when churn peaks will occur.
# â–ª Actionability:Recommendations for retention campaigns and automation.

# Business applications include:
#   - Prioritizing reactivation offers for at-risk customers.
#   - Aligning retention investment with forecasted churn cycles.
#   - Integrating churn probability into CLV-based segmentation.

# By predicting churn both at the individual and aggregate levels, this analysis enables companies to protect revenue streams,
# enhance loyalty, and transform customer analytics into a strategic competitive advantage.

################################################################ 0. Initial Setup ################################################################

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from prophet import Prophet
import os
from datetime import datetime
import warnings
warnings.filterwarnings("ignore")
sns.set(style="whitegrid")

# GitHub-Friendly Paths
clean_path = "Online_Retail_CLEAN.csv"
fig_dir = "figures/"
os.makedirs("output", exist_ok=True)
os.makedirs(fig_dir, exist_ok=True)

# LOAD DATASET SAFELY
if not os.path.exists(clean_path):
    raise FileNotFoundError(
        f"\nâŒ Clean dataset not found at: {clean_path}\n"
        f"â¡ï¸ Please run Steps 1â€“2 before executing Step 8.\n"
    )

df = pd.read_csv(clean_path)
df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])

print(f"âœ… Dataset loaded with {df.shape[0]:,} transactions.\n")

################################################################ 1. Build RFM Features ###########################################################

print("ğŸ“Š Building RFM customer features...")

snapshot_date = df['InvoiceDate'].max() + pd.Timedelta(days=1)

rfm = df.groupby('CustomerID').agg({
    'InvoiceDate': lambda x: (snapshot_date - x.max()).days,  # Recency
    'InvoiceNo'  : 'count',                                   # Frequency
    'TotalPrice' : 'sum'                                      # Monetary
}).reset_index()

rfm.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']

print("âœ… RFM features created successfully.\n")

################################################################ 2. Define Churn + Train Random Forest ########################################################

print("ğŸ¯ Defining churn labels...")

recency_threshold = 90
rfm['Churn'] = np.where(rfm['Recency'] > recency_threshold, 1, 0)

churn_rate = rfm['Churn'].mean() * 100
print(f"ğŸ“‰ Dataset churn rate: {churn_rate:.2f}% of customers.\n")

# Features and target
X = rfm[['Recency', 'Frequency', 'Monetary']]
y = rfm['Churn']

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

print("ğŸ§  Training Random Forest model...")

model = RandomForestClassifier(
    n_estimators=200,
    max_depth=6,
    random_state=42,
    class_weight='balanced'
)

model.fit(X_train, y_train)
y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred, output_dict=True)

print(f"âœ… Model Accuracy: {accuracy*100:.2f}%")
print("\nClassification Report:\n")
print(pd.DataFrame(report).T)

################################################################ 3. Feature Importance Plot ################################################################

feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': model.feature_importances_
}).sort_values(by='Importance', ascending=False)

fig, ax = plt.subplots(figsize=(8,5))
sns.barplot(
    x='Importance',
    y='Feature',
    data=feature_importance,
    palette="viridis",
    ax=ax
)
ax.set_title("Feature Importance â€“ Churn Prediction Model")
plt.tight_layout()

timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
importance_path = os.path.join(fig_dir, f"Churn_Feature_Importance_{timestamp}.png")
plt.savefig(importance_path, dpi=300, bbox_inches='tight')
plt.close()

print(f"ğŸ–¼ï¸ Feature importance figure saved: {importance_path}\n")

################################################################ 4. Interpretation â€“ Churn Model ########################################################

print("""
ğŸ” Analytical Interpretation: Churn Prediction Model

âœ… Accuracy = 100% â†’ Perfect separation because the churn label itself is based on Recency.
   The model is not overfitting â€” it is reproducing the deterministic rule in the data.

ğŸ“Š Predictor Insights:
1ï¸âƒ£ Recency â†’ Strongest predictor of churn (long inactivity = churn).
2ï¸âƒ£ Frequency â†’ Repeat buyers are more loyal.
3ï¸âƒ£ Monetary â†’ Higher spenders show greater retention levels.

ğŸ’¬ Strategic Meaning:
- Customers inactive >90 days should trigger structured reactivation flows.
- Frequent buyers are ideal candidates for loyalty initiatives.
- Monetary value helps prioritize retention investment (CLV alignment).
""")

################################################################ 5. Monthly Churn Time Series + Prophet Forecast #######################################################

print("ğŸ“ˆ Preparing monthly churn rate for forecasting...")

df['InvoiceMonth'] = df['InvoiceDate'].dt.to_period('M').dt.to_timestamp()

# Compute churn transitions: number of customers disappearing month-to-month
monthly_churn = (
    df.groupby(['InvoiceMonth', 'CustomerID'])['InvoiceDate']
    .max()
    .reset_index()
    .groupby('InvoiceMonth')['CustomerID']
    .nunique()
    .diff()
)

monthly_churn_rate = monthly_churn.fillna(0).reset_index()
monthly_churn_rate.columns = ['ds', 'y']
monthly_churn_rate['y'] = monthly_churn_rate['y'].abs()

print(f"âœ… Monthly churn time series created ({monthly_churn_rate.shape[0]} points).\n")

print("ğŸ”® Training Prophet model for churn forecasting...")
prophet = Prophet(yearly_seasonality=True, weekly_seasonality=False)
prophet.fit(monthly_churn_rate)

future = prophet.make_future_dataframe(periods=6, freq='M')
forecast = prophet.predict(future)

################################################################ 6. Save Prophet Forecast Plots ###############################################################

forecast_fig = prophet.plot(forecast)
plt.title("Churn Rate Forecast â€“ Prophet Model")
forecast_path = os.path.join(fig_dir, f"Churn_Forecast_{timestamp}.png")
forecast_fig.savefig(forecast_path, dpi=300, bbox_inches='tight')
plt.close()

components_fig = prophet.plot_components(forecast)
components_path = os.path.join(fig_dir, f"Churn_Forecast_Components_{timestamp}.png")
components_fig.savefig(components_path, dpi=300, bbox_inches='tight')
plt.close()

print(f"ğŸ–¼ï¸ Churn forecast figure saved: {forecast_path}")
print(f"ğŸ–¼ï¸ Churn components saved: {components_path}\n")

################################################################ 7. Interpretation â€“ Churn Forecast ###############################################################

print("""
ğŸ” Analytical Interpretation: Churn Forecasting

1ï¸âƒ£ Prophet identifies a *declining trend* in churn â†’ customer retention improving over time.
2ï¸âƒ£ Seasonal peaks occur right after high-spending months (Janâ€“Feb).
3ï¸âƒ£ Forecast uncertainty widens as horizon increases â€” typical for retail data.

ğŸ’¡ Strategic Insight:
- Reactivation campaigns should be deployed immediately after seasonal peaks.
- Boost loyalty incentives in slow months.
- Monitor churn forecasts monthly for tactical adjustments.
""")

################################################################ 8. Strategic Summary ###############################################################

print("""
ğŸ“ˆ Strategic Summary: Churn Intelligence System

ğŸ§© Two complementary layers:
- Random Forest â†’ *Who* is likely to churn?
- Prophet â†’ *When* churn will rise?

ğŸš€ Business Recommendations:
1ï¸âƒ£ Combine churn probability with CLV segmentation for retention prioritization.
2ï¸âƒ£ Trigger personalized workflows for high-risk segments.
3ï¸âƒ£ Re-train the Prophet model quarterly as new data arrives.

ğŸ’¬ Final Takeaway:
Reducing churn by just **5â€“10%** can lift total CLV by **25%+**.
This integrated churn prediction + forecasting framework provides a data-driven base
for proactive customer retention.
""")

print("âœ… Full churn intelligence analysis completed successfully!")
